<rss version="2.0">
    <channel>    
        <title>Влад Костянецкий</title>
        <description>Привет! Меня зовут Влад, я — разработчик приложений для бизнеса.</description>
        <language>ru</language>
        <link>https://kostyanetsky.ru</link>
        <lastBuildDate>Thu, 14 Jan 2021 10:15:16 +0700</lastBuildDate>
        
        <item>
            <title>Рекурсивный поиск по файлам</title>
            <link>https://kostyanetsky.ru/notes/recursive-search/</link>
            <guid isPermaLink="false">note-recursive-search</guid>
            <pubDate>Thu, 14 Jan 2021 10:15:16 +0700</pubDate>
            <description><p class="measure-wide">Время назад я <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/vulnerabilities/">примеривался</a> к поискам уязвимостей в коде скриптами на bash (звучит грозно, но это просто рекурсивный поиск текста с помощью регулярных выражений). Скрипты-то я тогда написал, но, как сегодня понял — несколько... Ректально, кхм. Для решения хватает одного egrep! То есть из связки find, xargs и egrep можно выкинуть два компонента из трех.</p>
<p class="measure-wide">Например, сегодня у нас возникла проблема: конфигурация перестала собираться в последнем релизе EDT. Подозрение пало на битые GUID — ссылки на объекты метаданных, удаленные из конфигурации. Платформа не всегда справляется с их вычисткой после того, как удалит сами объекты; я уже пару раз писал про это (например, <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/designer-error-investigation/">здесь</a> или <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/unresolved-gopher/">вот тут</a>).</p>
<p class="measure-wide">В общем, мы решили порыться в выгрузке конфигурации — найти GUID'ы и оценить, все ли они находятся там, где положено. Общее решение — одна-единственная команда:</p>
<pre><code>egrep -rn '.{8}-.{4}-.{4}-.{4}-.{12}' dump
</code></pre>
<p class="measure-wide">Ключ r включает рекурсивный поиск, ключ n — заставляет утилиту пристегнуть к найденной строке не только имя файла, в котором найдена строка, но и номер самой строки. Последний параметр, dump — имя директории, где нужно искать.</p>
<p class="measure-wide">Регулярку можно сделать точнее, но и такой за глаза хватает. Что до ложных срабатываний (то есть GUID, которые не являются битыми ссылками) — их легко отсеять через пайп. Например, скрипт ниже не будет выводить строки с GUID, в которых есть подстрока «uuid»:</p>
<pre><code>egrep -rn '.{8}-.{4}-.{4}-.{4}-.{12}' dump | grep -v 'uuid'
</code></pre></description>
        </item>
        
        <item>
            <title>Старый добрый DATETIME</title>
            <link>https://kostyanetsky.ru/notes/old-but-gold/</link>
            <guid isPermaLink="false">note-old-but-gold</guid>
            <pubDate>Wed, 11 Nov 2020 17:00:50 +0700</pubDate>
            <description><p class="measure-wide">Порылся в сети по поводу типов дат в MS SQL Server и в целом вопроса «почему 1С до сих пор носится со своим смещением» больше не имею. Люди пишут о целой пачке проблем с DATETIME2:</p>
<ol class="measure-wide">
<li>Недоступна базовая математика. Без дополнительных финтов ушами не выйдет посчитать разницу между двумя датами, прибавить к дате день и так далее.</li>
<li>Стандартные функции по-прежнему возвращают старый добрый DATETIME (например, DATEADD). Если данные хранятся в DATETIME2 — потребуется конвертация.</li>
<li>Поля с этим типом <a class="link blue dim bb" href="https://sqlperformance.com/2016/04/sql-performance/surprises-dateadd">неважно</a> индексируются, так как каждое значение DATETIME2 хранится задом наперед (сначала время, потом дата). В итоге СУБД промахивается с оценкой количества строк, которое может вернуть запрос, и строит для него неэффективный план выполнения.</li>
</ol>
<p class="measure-wide">Подробнее о всем этом можно прочитать на <a class="link blue dim bb" href="https://towardsdatascience.com/datetime2-why-you-should-not-use-it-70e50ae2bab9">Towards Data Science</a> или, например, на <a class="link blue dim bb" href="https://www.sqlservercentral.com/forums/topic/why-do-some-dbas-avoid-datetime2">SQL Server Central</a>.</p></description>
        </item>
        
        <item>
            <title>Потерянное время</title>
            <link>https://kostyanetsky.ru/notes/lost-time/</link>
            <guid isPermaLink="false">note-lost-time</guid>
            <pubDate>Tue, 10 Nov 2020 19:06:41 +0700</pubDate>
            <description><p class="measure-wide">В MS SQL Server поля DATETIME <a class="link blue dim bb" href="https://docs.microsoft.com/ru-ru/dotnet/api/system.data.sqltypes.sqldatetime.minvalue?view=dotnet-plat-ext-3.1">не могут</a> хранить даты раньше 1753-го года. Например, если попытаться записать в базу 01.01.0001 — получим ругань на out-of-range value. Я считал это забавным для такой почтенной СУБД рудиментом, пока случайно не наткнулся на <a class="link blue dim bb" href="https://stackoverflow.com/questions/3310569/what-is-the-significance-of-1-1-1753-in-sql-server">причину</a>.</p>
<p class="measure-wide">Если вкратце, в 1752-м году Великобритания внедрила у себя Григорианский календарь, и в процессе у них из летосчисления пропало одиннадцать дней. Это породило проблему: вот хочет юзер посчитать разницу в днях между 1653-м и 1753-м годом — что делать будем? Учтем потеряшек? Проигнорируем? Сделаем какие-то хинты или настройки?</p>
<p class="measure-wide">Видимо, чтобы не городить неоднозначные механизмы, разработчики СУБД решили вопрос радикально — усечением доступного диапазона дат. А для тех, для кого это проблема, есть DATETIME2, который никаких ограничений не имеет.</p>
<p class="measure-wide">Платформа 1С пока использует DATETIME, а чтобы не иметь головной боли с хранением дат раньше 1753-го года — применяет специальный <a class="link blue dim bb" href="https://its.1c.ru/db/metod8dev/content/4055/hdoc">костыль</a>. Если в двух словах, когда платформа пишет даты в БД, то тихой сапой прибавляет к каждой две тысячи лет, а когда читает — вычитает обратно. То есть в 1С пользователь видит 01.01.2000, а в БД на самом деле хранится 01.01.4000.</p>
<p class="measure-wide">Любопытно, почему 1C до сих пор не выкинула эту штуку и не переехала со «старого» DATETIME на DATETIME2? Возможно, тут есть какие-то подводные камни, но среди разработчиков самой СУБД сомнений <a class="link blue dim bb" href="https://stackoverflow.com/questions/3310569/what-is-the-significance-of-1-1-1753-in-sql-server/3310627#3310627">не заметно</a>:</p>
<blockquote>
<p class="measure-wide">Your great great great great great great great grandfather should upgrade to SQL Server 2008 and use the DateTime2 data type, which supports dates in the range: 0001-01-01 through 9999-12-31.</p>
<p class="measure-wide"><em>Joe Stefanelli (SQL Server developer)</em></p>
</blockquote>
<p class="measure-wide">Возможно, это просто на дне приоритетов. Добавление и удаление двух тысяч лет для каждой даты, конечно, увеличивает нагрузку на оборудование, но на фоне остального она теряется.</p></description>
        </item>
        
        <item>
            <title>Халк удалять!</title>
            <link>https://kostyanetsky.ru/notes/hulk-removes/</link>
            <guid isPermaLink="false">note-hulk-removes</guid>
            <pubDate>Mon, 09 Nov 2020 16:03:07 +0700</pubDate>
            <description><p class="measure-wide">На <a class="link blue dim bb" href="https://postgrespro.ru/education/courses/DBA1">курсе</a> по PostgreSQL узнал смешную деталь: в 10-й версии СУБД разработчики переименовали папку pg_xlog (журналы предзаписи) в pg_wal, а папку pg_clog (статусы транзакций) — в pg_xact.</p>
<p class="measure-wide">Знаете, почему? Из-за не слишком опытных, но уже достаточно смелых администраторов, которые триггерились на слово «log» в названии папки. Мол, мне нужно место на диске освободить, а тут СУБД забила всё своими дурацкими логами. Некогда разбираться, rm -rf их и порядок!</p>
<p class="measure-wide">В общем, в трубу одновременно вылетала и защита работы с данными в буферном кэше, и многоверсионность. После чего кластер умирал в муках. Свободного места на диске получалось много, но радоваться этому, боюсь, приходилось недолго :-)</p></description>
        </item>
        
        <item>
            <title>Время для прогулки</title>
            <link>https://kostyanetsky.ru/notes/time-to-wink/</link>
            <guid isPermaLink="false">note-time-to-wink</guid>
            <pubDate>Mon, 02 Nov 2020 15:36:28 +0700</pubDate>
            <description><p class="measure-wide">Как понять, что надо сделать перерыв в работе? Скажем так: если ваш скрипт внезапно начал вам подмигивать — точно пора проветриться.</p>
<p class="measure-wide"><img alt="Привет!" src="https://kostyanetsky.ru/notes/time-to-wink/wink.png"/></p></description>
        </item>
        
        <item>
            <title>Расследование ошибки в Конфигураторе</title>
            <link>https://kostyanetsky.ru/notes/designer-error-investigation/</link>
            <guid isPermaLink="false">note-designer-error-investigation</guid>
            <pubDate>Sat, 31 Oct 2020 12:38:15 +0700</pubDate>
            <description><p class="measure-wide">Итак, Конфигуратор выдает ошибку; нужно её исправить или обойти. Это потенциально неприятный расклад: у нас нет никакого доступа к коду приложения. Тем не менее, чтобы решить проблему — важно понять, что именно делал Конфигуратор до сбоя и почему он не справился.</p>
<p class="measure-wide">Что может с этим помочь?</p>
<p class="measure-wide">Первое — сам текст ошибки. Нередко его вполне достаточно, чтобы мысли двинулись в правильном направлении. Если причиной сбоя стал запрос, то в ошибке будет ещё и сообщение от СУБД.</p>
<p class="measure-wide">Второе — технологический журнал по событиям EXCP, SDBL и DBMSSQL (DBPOSTGRS?) для t:applicationName=Designer. Из него мы получим информацию об исключениях внутри Конфигуратора и данные запросов, которые он выполняет (нередко они и есть причина ошибки).</p>
<p class="measure-wide">Кроме того, может пригодиться трассировка запросов к базе данных. Если используется MS SQL, то трассировку можно получить через Extended Events — конкретно, нас интересуют события error_reported, rpc_completed и sql_batch_completed. Общий принцип тот же — ловим ошибки выполнения запросов и сами запросы. </p>
<p class="measure-wide">Разберем пример — может, не самый показательный, зато свежий.</p>
<p class="measure-wide">Контекст — конфигурация, использующая <a class="link blue dim bb" href="https://v8.1c.ru/platforma/razdelenie-dannyh/">разделение данных</a>. Её база данных «нарезана» на кусочки (области данных), каждый из которых ничего не знает о своих соседях — сколько их, какого они размера и так далее. При этом в БД есть и общие данные — например, справочники, к которым можно обратиться из любой области. Как правило, это разная техническая информация — например, перечень объектов метаданных.</p>
<p class="measure-wide">Задача — исключить справочник FileStorageVolumes из основного разделителя. Сейчас этот справочник — разделенный: то есть, его данные от области к области будут различаться. Нам нужно сделать так, чтобы содержимое справочника стало одинаковым для всех областей.</p>
<p class="measure-wide">Задача несложная, так как таблица справочника пуста — ни одна из областей ничего в нем не хранит. Что же, применяем <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/designer-error-investigation/setup.png">настройку</a> и:</p>
<p class="measure-wide"><img alt="Исключение" src="https://kostyanetsky.ru/notes/designer-error-investigation/error.png"/></p>
<p class="measure-wide">В <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/designer-error-investigation/error.txt">тексте</a> исключения есть сообщения: одно от платформы, второе от СУБД. Первое озадачивает: то есть как это данные не уникальны? Справочник же пуст, никаких данных нет. Возможно, проблема в каких-то вспомогательных структурах, не связанных с содержимым справочника напрямую.</p>
<p class="measure-wide">Сообщение СУБД более внятное: MS SQL Server хотела создать уникальный индекс для таблицы _DataHistorySettingsNG, но не смогла, так как сочетания индексируемых полей оказались неуникальны. Приводится даже конкретное значение, из-за которого не получилось создать индекс: это NULL.</p>
<p class="measure-wide">Выводы?</p>
<ol class="measure-wide">
<li>Очевидно, что проблема возникла в ходе реструктуризации. Во-первых, именно её мы и делали. Во-вторых, на это указывает и операция CREATE UNIQUE INDEX (создание индексов в таблицах — часть реструктуризации), и название проблемной таблицы: в нём есть постфикс NG (его получают копии таблиц, которые создаются при реструктуризации; если она проходит успешно, то платформа удаляет исходную таблицу и переименовывает копию).</li>
<li>Проблема возникла с настройками механизма истории данных (_DataHistorySettings). Там хранится статус каждого объекта метаданных: нужно или нет вести историю данных для объекта, его полей и полей его табличных частей (если они есть).</li>
</ol>
<p class="measure-wide">Последнее объясняет, почему проблема уникальности возникла на пустом справочнике: настройки истории данных для объекта хранятся независимо от того, есть в объекте какие-то данные или нет. Если посмотреть на таблицу с настройками, там всего три поля: _MetadataId (ID объекта метаданных), _Content (значения настроек) и _Fld626 (разделитель области).</p>
<p class="measure-wide">До реструктуризации данные имеют примерно такой вид:</p>
<p class="measure-wide"><img alt="Таблица _DataHistorySettings" src="https://kostyanetsky.ru/notes/designer-error-investigation/table.png"/></p>
<p class="measure-wide">Однако потом эта картина изменилась. Когда мы исключили справочник из состава общего реквизита, конфигуратор запустил реструктуризацию: создал таблицу _DataHistorySettingsNG, перенес в неё данные из _DataHistorySettings и установил значение поля _Fld626 в NULL всем записям, которые относятся к справочнику FileStorageVolumes.</p>
<p class="measure-wide">К чему это привело? А вот к чему: для справочника FileStorageVolumes появился целый ворох настроек, которые не относятся к какой-либо области. Это само по себе звучит нездорово, но настоящие проблемы начались, когда Конфигуратор попытался создать для таблицы кластерный индекс: он <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/designer-error-investigation/index.png">строится</a> по полям _MetadataId и _Fld626, является уникальным и, соответственно, не может быть создан — в таблице множество записей, у которых различается только поле _Content, а _MetadataId и _Fld626 — гарантированно идентичны.</p>
<p class="measure-wide">Для очистки совести посмотрим <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/designer-error-investigation/20103116.log">техжурнал</a> (я вычистил оттуда нерелевантные события и другую постороннюю информацию). Наши догадки подтверждается: видим, как Конфигуратор создает и заполняет таблицу _DataHistorySettingsNG, пытается проиндексировать её, но получает ошибку и удаляет. В <a class="link blue dim bb" href="https://kostyanetsky.ru/notes/designer-error-investigation/20103116.png">трассировке</a> СУБД примерно та же картина.</p>
<p class="measure-wide">На этом интересное заканчивается, так как решение достаточно очевидно: удаляем настройки истории данных для справочника во всей областях данных и повторяем реструктуризацию. Ошибку это не исправит, конечно; по хорошему, Конфигуратор должен предсказывать такую ситуацию и выдавать адекватное сообщение — как, например, при удалении измерения регистра сведений, которое приводит к нарушению уникальности измерений для записей регистра. Однако задача будет решена.</p>
<p class="measure-wide">В общем, готово — мы великолепны!</p></description>
        </item>
        
        <item>
            <title>Расчет количества исключений по ТЖ</title>
            <link>https://kostyanetsky.ru/notes/excp-number-by-minutes/</link>
            <guid isPermaLink="false">note-excp-number-by-minutes</guid>
            <pubDate>Sat, 24 Oct 2020 12:00:12 +0700</pubDate>
            <description><p class="measure-wide">Ещё <a class="link blue dim bb" href="https://github.com/vkostyanetsky/ScriptsFor1C/blob/master/Технологический%20журнал/ExceptionsNumberByMinutes.sh">скрипт</a>. Считает количество исключений в минуту и строит топ, по которому видно распределение. Можно быстро оценить периоды, когда программы сбоили особенно яростно.</p>
<p class="measure-wide">По ходу дела столкнулся в двумя любопытными проблемами, которые меня порядком сбили с толку. Во-первых, я почему-то был уверен, что uniq -c группирует строки вне зависимости от того, где в потоке данных они встречаются. Рассмотрим пример:</p>
<pre><code>банан
банан
груша
банан
</code></pre>
<p class="measure-wide">Я думал, что если отдать эти данные uniq -c, то она сгруппирует одинаковые строки, посчитает количество повторений и выдаст примерно такое:</p>
<pre><code>3 банан
1 груша
</code></pre>
<p class="measure-wide">Но на деле получилось так:</p>
<pre><code>2 банан
1 груша
1 банан
</code></pre>
<p class="measure-wide">Вывод: утилита uniq ожидает, что повторяющиеся строки идут одна за другой. Если строка отличается от предыдущей — она начинает считать счетчик совпадений для неё с нуля. То есть, чтобы получить тот результат, на который я рассчитывал — нужно сначала отсортировать данные, и только потом передавать их в uniq.</p>
<p class="measure-wide">Второй проблемой стала утилита sed. С помощью неё я пытался удалить из потока данных всё, кроме часов и минут (текст попытки на 12-й строке скрипта). Однако часть событий упорно не попадали под регулярку несмотря на то, что визуально никак не отличались. Я промаялся кучу времени и здорово разозлился, но потом вспомнил про существование <a class="link blue dim bb" href="https://ru.wikipedia.org/wiki/Маркер_последовательности_байтов">BOM</a>. Вычистил их и дальше все пошло как по маслу.</p>
<p class="measure-wide">BOM используется во всех файлах ТЖ (в этом можно убедиться, например, с помощью <a class="link blue dim bb" href="https://github.com/vkostyanetsky/ScriptsFor1C/blob/master/Технологический%20журнал/LogFilesWithoutBOM.sh">скрипта</a>). То есть каждый лог начинается с особых символов, которых невооруженным глазом не увидеть и которые могут помешать обработать первую строку файла (так как эти самые символы не будут попадать под условие регулярного выражения).</p>
<p class="measure-wide">Вывод: проще всего удалять BOM по умолчанию, не оценивая рисков для каждой конкретной задачи. Да, иногда это будет лишним (например, решению задачи по тексту выше через grep BOM никак не мешает). Но я не люблю сюрпризы. Кроме того, несколько тактов процессора на простую замену — явно выгоднее, чем эквивалент в сгоревших нервных клетках и потерянном времени.</p></description>
        </item>
        
        <item>
            <title>Профессиональная деформация</title>
            <link>https://kostyanetsky.ru/notes/nerdview/</link>
            <guid isPermaLink="false">note-nerdview</guid>
            <pubDate>Mon, 19 Oct 2020 18:35:56 +0700</pubDate>
            <description><p class="measure-wide"><img alt="Чат с дочкой" src="https://kostyanetsky.ru/notes/nerdview/telegram.png"/></p>
<p class="measure-wide">Дочка пишет о своих планах — мол, не теряй меня. А у меня профессиональная деформация: этот вполне нормальный чат мой мозг упорно воспринимает как код на Gherkin. Просто какой-то неправильный, что ли, хочется быстренько пофиксить :-)</p>
<pre><code>И я выхожу
Тогда я в школе
И я выхожу
Тогда я покачаюсь
</code></pre>
<p class="measure-wide">Мы на этом языке пишем автотесты нашей конфигурации для <a class="link blue dim bb" href="https://github.com/Pr-Mex/vanessa-automation">Vanessa Automation</a>. Вроде не так уж много я их накатал (сравнивая с некоторыми коллегами — баловался, считай). Но, видимо, достаточно.</p></description>
        </item>
        
        <item>
            <title>Запросы и ожидания на блокировках</title>
            <link>https://kostyanetsky.ru/notes/queries-and-lock-waits/</link>
            <guid isPermaLink="false">note-queries-and-lock-waits</guid>
            <pubDate>Mon, 19 Oct 2020 06:23:06 +0700</pubDate>
            <description><p class="measure-wide">Набросал ещё два скрипта для анализа ТЖ: <a class="link blue dim bb" href="https://github.com/vkostyanetsky/ScriptsFor1C/blob/master/Технологический%20журнал/LongestQueries.sh">первый</a> строит топ тяжелых запросов к MS SQL, <a class="link blue dim bb" href="https://github.com/vkostyanetsky/ScriptsFor1C/blob/master/Технологический%20журнал/LongestLockWaitsByRegions.sh">второй</a> — топ длительных ожиданий на блокировках.</p>
<p class="measure-wide">Тяжелые запросы определяются по продолжительности событий DBMSSQL. То есть, чем дольше выполнялся запрос — тем вероятнее, что в процессе он слопал кучу ресурсов. Обычно это так и есть, хотя для нормальной диагностики нужно смотреть трассировку.</p>
<p class="measure-wide">Ожидания на блокировках тоже считаются по продолжительности. При этом скрипт проверяет, что у события TLOCK заполнено свойство WaitConnections — то есть платформа действительно ждала возможности установить блокировку, а не просто потратила какое-то время на её установку.</p></description>
        </item>
        
        <item>
            <title>Новый скрипт топа исключений</title>
            <link>https://kostyanetsky.ru/notes/top-exceptions-v2/</link>
            <guid isPermaLink="false">note-top-exceptions-v2</guid>
            <pubDate>Sat, 17 Oct 2020 13:25:02 +0700</pubDate>
            <description><p class="measure-wide">Переписал <a class="link blue dim bb" href="https://github.com/vkostyanetsky/ScriptsFor1C/blob/master/Технологический%20журнал/FrequentExceptions.sh">скрипт</a> на баше, строящий топ исключений по собранному ТЖ: хотел решить эту задачу как-то попроще.</p>
<p class="measure-wide">В итоге выкинул из кода возню с заменой начала события на маркер gawk для разделения записей (его можно сразу задать регулярным выражением) и перенес больше логики в скрипт для gawk (так нагляднее, особенно если потом захочется её расширить). </p>
<p class="measure-wide">Получилось явно лучше, чем <a class="link blue dim bb" href="https://gist.github.com/vkostyanetsky/47e02e199bb32082c4d5019ca88233c0">было</a> — во всяком случае, логика выглядит понятнее. Изначально, правда, я хотел скорее сократить скрипт в размере и получить что-то вроде:</p>
<pre><code>grep -hoP ",EXCP,.*\KDescr=.*" */*.log | uniq -c | sort -rn
</code></pre>
<p class="measure-wide">То есть фильтруем только строки с событием EXCP, отрезаем всё до описания ошибки и группируем с помощью uniq. По-моему, очень изящно.</p>
<p class="measure-wide">Однако описание у EXCP может быть многострочным. То есть мы будем время от времени терять часть данных, нужных для расследования (всё описание после первого же перевода строки). Как решить эту проблему так, чтобы скрипт не разбарабанило втрое — я пока не придумал :-)</p></description>
        </item>
        
    </channel>
</rss>